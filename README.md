# GenAI_TTS-STS-Voicecloning-
A complete end-to-end pipeline that transforms PDF books into audiobooks in your own cloned voice.

This project takes a **PDF book** and turns it into an **audiobook in your cloned voice**.  
It uses multiple APIs for **text extraction, TTS, voice cloning, and transcription**.  

---

## ✨ Features
- Extracts text from a PDF into **page-by-page `.txt` files**  
- Converts text into **synthetic speech (Camb.ai TTS)**  
- Transcribes audio files back into text (**Deepgram**)  
- Clones your real voice (**Async.ai**)  
- Generates audiobook audio **in your own cloned voice**  

---

## 📂 Project Structure

```
.
├── pdf_reader.py          # Extracts text from PDF -> Text/*.txt
├── tts_converter.py       # Converts text into synthetic speech using Camb.ai
├── transcribe_audio.py    # Transcribes generated audio files using Deepgram
├── clone_my_voice.py      # Clones your voice using Async.ai
├── text_in_my_voice.py    # Converts transcripts into your cloned voice
├── Text/                  # Stores extracted .txt files from PDF
├── Audio/                 # Stores TTS audio generated by Camb.ai
├── transcriptions/        # Stores Deepgram transcripts
├── My_Voice/              # Final audiobook audio in your voice
├── .env                   # Environment variables (API keys, configs)
└── README.md              # Documentation
```

---

## 🔑 Requirements

- Python 3.9+
- Virtual environment recommended
- API keys from:
  - [Camb.ai](https://camb.ai/) – TTS
  - [Deepgram](https://deepgram.com/) – transcription
  - [Async.ai](https://async.ai/) – voice cloning + custom TTS  

---

## ⚙️ Installation

1. Clone the repo:
   ```bash
   git clone https://github.com/yourusername/pdf-audiobook-voice.git
   cd pdf-audiobook-voice
   ```

2. Create virtual environment and install dependencies:
   ```bash
   python -m venv venv
   source venv/bin/activate   # Linux/Mac
   venv\Scripts\activate      # Windows

   pip install -r requirements.txt
   ```

3. Create a `.env` file with your API keys and settings:

   ```ini
   # PDF input
   PDF_FILE=life_3_0.pdf
   TEXT_FOLDER=Text
   BASE_NAME=life_3_0_page_

   # Camb.ai (TTS)
   CAMB_API_KEY=your_camb_ai_key
   CAMB_VOICE_ID=20305
   CAMB_LANGUAGE=1
   AUDIO_FOLDER=Audio
   FILE_NAME=life_3_0
   PAGE_SEPARATOR=_page_

   # Deepgram (Transcription)
   DEEPGRAM_API_KEY=your_deepgram_key
   TRANSCRIPTIONS_FOLDER=transcriptions

   # Async.ai (Voice Cloning & TTS)
   ASYNC_API=your_async_ai_key
   VOICE_ID_ASYNC=your_voice_id  # after cloning
   SAMPLE_AUDIO=sample_audio.wav
   OUTPUT_FOLDER=My_Voice
   ```

---

## ▶️ Usage

### 1. Extract PDF text
Convert PDF into per-page `.txt` files:
```bash
python pdf_reader.py
```
👉 Creates files like `Text/life_3_0_page_1.txt`, `Text/life_3_0_page_2.txt`, etc.

---

### 2. Convert text → synthetic speech
Generate TTS audio using **Camb.ai**:
```bash
python tts_converter.py
```
👉 Saves audio in `Audio/` as `.wav` files.

---

### 3. Transcribe audio
Convert TTS audio back into text using **Deepgram**:
```bash
python transcribe_audio.py
```
👉 Creates transcript `.txt` files in `transcriptions/`.

---

### 4. Clone your voice
Upload your sample audio (`sample_audio.wav`) to **Async.ai**:
```bash
python clone_my_voice.py
```
👉 Returns a `voice_id` in the response — copy it into `.env` as `VOICE_ID_ASYNC`.

---

### 5. Generate audiobook in your voice
Use Async.ai to generate audiobook audio in your cloned voice:
```bash
python text_in_my_voice.py
```
👉 Final audiobook segments saved in `My_Voice/`.

---

## 📝 Notes
- `pdf_reader.py` skips the first 10 pages by default — adjust if needed.  
- `tts_converter.py` currently processes the **first 10 sentences** of the first page as a demo — extend to full text for complete audiobook.  
- Async.ai expects **raw PCM or WAV output format** internally but returns audio you can save as `.mp3`.  
- Be mindful of API rate limits and token quotas.  

---

## 🚀 Future Improvements
- Merge all `.mp3` outputs into a **single audiobook file**  
- Add progress bars instead of print statements  
- Support multiple voice styles (e.g., narration vs. dialogue)  
- Containerize with Docker for easy deployment  
